import streamlit as st
import plotly.express as px
import os
import zipfile
from transformers import BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer
import torch
from accelerate import Accelerator
from transformers import BitsAndBytesConfig
import base64
from collections import Counter
import re
import pandas as pd
import joblib 
import numpy as np 
from pathlib import Path

# ZIP dosyasƒ± yollarƒ± ve √ßƒ±kartƒ±lacak klas√∂r
# L√ºtfen t√ºm ZIP ve g√∂rsel dosyalarƒ±nƒ±n bu klas√∂rde olduƒüundan emin olun.
model_zip_paths = {
    "bert_tokenizer_zip_path": "C:\\random.modeller\\bert_alzheimer_tokenizer.zip",
    "zamir_modeli_zip_path": "C:\\random.modeller\\zamir.modeli.zip",
    "sond_zip_path": "C:\\random.modeller\\sond.zip",
    "bert_alzheimer_tokanizer_zip_path": "C:\\random.modeller\\bert_alzheimer_tokenizer.zip",
    "untitled7_zip_path": "C:\\random.modeller\\Untitled7.zip"
}
zamir_extract_dir = "C:\\random.modeller\\zamir.modeli"

# sond.py modeli i√ßin gerekli dosyalar
id2label = {0: "Normal", 1: "Alzheimer"}

# ZIP dosyasƒ±nƒ± √ßƒ±kartma i≈ülemini bir kez yapalƒ±m
def extract_zip(zip_path, extract_dir):
    if not os.path.exists(extract_dir):
        os.makedirs(extract_dir, exist_ok=True)
    
    try:
        if not zipfile.is_zipfile(zip_path):
            st.error(f"Dosya bir ZIP dosyasƒ± deƒüil: {zip_path}. L√ºtfen dosya t√ºr√ºn√º kontrol edin.")
            st.stop()

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)
        # st.success mesajƒ± kaldƒ±rƒ±ldƒ±
    except FileNotFoundError:
        st.error(f"Model ZIP dosyasƒ± bulunamadƒ±: {zip_path}. L√ºtfen dosya yolunu kontrol edin.")
        st.stop()
    except zipfile.BadZipFile:
        st.error(f"Ge√ßersiz ZIP dosyasƒ±: {zip_path}. Dosyanƒ±n bozuk olmadƒ±ƒüƒ±ndan emin olun.")
        st.stop()
    except Exception as e:
        st.error(f"Dosya √ßƒ±kartƒ±lƒ±rken bir hata olu≈ütu ({os.path.basename(zip_path)}): {e}")
        st.stop()

# T√ºm tanƒ±mlƒ± ZIP dosyalarƒ±nƒ± √ßƒ±kart
# st.info mesajƒ± kaldƒ±rƒ±ldƒ±
for path in model_zip_paths.values():
    extract_zip(path, zamir_extract_dir)


# ----------------------------------------------------
# MODELLERƒ∞N Y√úKLENMESƒ∞ VE √ñNBELLEKLEME
# ----------------------------------------------------

@st.cache_resource
def load_all_models():
    quantization_config = BitsAndBytesConfig(load_in_8bit=True)
    zamir_model, zamir_tokenizer, sond_model, sond_tokenizer = None, None, None, None

    try:
        zamir_model = BertForSequenceClassification.from_pretrained(
            zamir_extract_dir,
            quantization_config=quantization_config,
            device_map="auto"
        )
        zamir_tokenizer = BertTokenizer.from_pretrained(zamir_extract_dir)
        
        sond_model = AutoModelForSequenceClassification.from_pretrained(zamir_extract_dir, num_labels=2)
        sond_tokenizer = AutoTokenizer.from_pretrained(zamir_extract_dir)

        zamir_model.eval()
        sond_model.eval()
        # st.success mesajƒ± kaldƒ±rƒ±ldƒ±
    except Exception as e:
        st.error(f"Modeller y√ºklenirken bir hata olu≈ütu: {e}. Dosya adlarƒ±nƒ±n ve klas√∂r i√ßeriƒüinin doƒüru olduƒüundan emin olun.")
        st.stop()
        
    return zamir_model, zamir_tokenizer, sond_model, sond_tokenizer

# Modelleri ve tokenizer'larƒ± bir kez y√ºkle
(zamir_model, zamir_tokenizer, 
 sond_model, sond_tokenizer) = load_all_models()

# Cihaz belirleme
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ----------------------------------------------------
# ANALƒ∞Z FONKSƒ∞YONLARI
# ----------------------------------------------------

def sond_analizi_yap(metin, model, tokenizer):
    if not model or not tokenizer:
        return []
    
    metin_temiz = re.sub(r"[.,!?;:\"‚Äú‚Äù‚Äô'()]", " ", metin.lower())
    kelimeler = [w for w in metin_temiz.split() if w.strip()]
    sayac = Counter(kelimeler)
    toplam = len(kelimeler)
    
    if toplam == 0:
        return []

    sonuc_df = pd.DataFrame(columns=["Kelime", "Tahmin"])
    
    for kelime, adet in sayac.items():
        giris = metin.replace(kelime, f"[VURGULANMI≈û_KELƒ∞ME] {kelime} [VURGULANMI≈û_KELƒ∞ME]")
        enc = tokenizer(giris, return_tensors="pt", padding="max_length", truncation=True, max_length=64).to(device)
        logits = model(**enc).logits
        tahmin_etiketi = int(logits.argmax(dim=1).item())
        tahmin_metni = id2label[tahmin_etiketi]
        sonuc_df.loc[len(sonuc_df)] = [kelime, tahmin_metni]

    return sonuc_df

def konsolide_analiz_yap(metin, zamir_model, zamir_tokenizer, sond_model, sond_tokenizer):
    risk_seviyesi = 0 # 0: D√º≈ü√ºk, 1: Orta, 2: Y√ºksek

    # 1. Zamir Modeli Tahmini
    if zamir_model and zamir_tokenizer:
        inputs = zamir_tokenizer(metin, return_tensors="pt", truncation=True, padding=True, max_length=512)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = zamir_model(**inputs)
            logits = outputs.logits
            prediction = torch.argmax(logits, dim=1).item()
        
        if prediction == 1: # Orta Risk
            risk_seviyesi = max(risk_seviyesi, 1)
        elif prediction == 2: # Y√ºksek Risk
            risk_seviyesi = max(risk_seviyesi, 2)
            
    # 2. Sond.py Modeli Analizi
    if sond_model and sond_tokenizer:
        sond_sonuc_df = sond_analizi_yap(metin, sond_model, sond_tokenizer)
        if not sond_sonuc_df.empty:
            alzheimer_kelime_sayisi = (sond_sonuc_df['Tahmin'] == 'Alzheimer').sum()
            toplam_kelime = len(sond_sonuc_df)
            if toplam_kelime > 0 and (alzheimer_kelime_sayisi / toplam_kelime) > 0.1: # %10'dan fazlaysa
                risk_seviyesi = max(risk_seviyesi, 1)
            if toplam_kelime > 0 and (alzheimer_kelime_sayisi / toplam_kelime) > 0.25: # %25'ten fazlaysa
                risk_seviyesi = max(risk_seviyesi, 2)

    # 3. Manuel Zamir Analizi
    zamirler = ["ben", "sen", "o", "biz", "siz", "onlar"]
    zamir_sonuc = {zamir: metin.lower().split().count(zamir) for zamir in zamirler}
    toplam_zamir = sum(zamir_sonuc.values())
    if toplam_zamir > 0:
        ben_oran = zamir_sonuc.get("ben", 0) / toplam_zamir
        o_oran = zamir_sonuc.get("o", 0) / toplam_zamir
        if ben_oran > 0.4 or o_oran > 0.3:
            risk_seviyesi = max(risk_seviyesi, 1)

    return risk_seviyesi

# ----------------------------------------------------
# STREAMLIT ARAY√úZ KISMI
# ----------------------------------------------------

st.set_page_config(page_title="Alzheimer Tahmini", layout="wide")

def get_base64_image(image_path):
    if os.path.exists(image_path):
        with open(image_path, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()
    return None

logo_path = r"C:\veri.modelleri\atom.logo.jpeg"
logo_base64 = get_base64_image(logo_path)

if logo_base64:
    st.sidebar.markdown(
        f"""
        <div style="display: flex; justify-content: center; padding: 10px 0;">
            <img src="data:image/jpeg;base64,{logo_base64}" style="width:200px; border-radius:10px;">
        </div>
        """,
        unsafe_allow_html=True
    )
else:
    st.sidebar.error("Logo dosyasƒ± bulunamadƒ±. L√ºtfen dosya yolunu kontrol edin.")

st.sidebar.title("Men√º")

sayfa = st.sidebar.radio(
    label="",
    options=["üè† Ana Sayfa", "üß† Analiz Yap", "‚ùì Nasƒ±l √áalƒ±≈üƒ±r", "üìû ƒ∞leti≈üim"],
    label_visibility="hidden"
)

if sayfa == "üè† Ana Sayfa":
    st.title("üß† Alzheimer Risk Tahmini")
    st.subheader("Doƒüal Dil ƒ∞≈üleme Tabanlƒ± Bili≈üsel Dil Analizi")
    st.markdown("""
        Bu uygulama, kullanƒ±cƒ±dan alƒ±nan metinleri zamir kullanƒ±mƒ±, c√ºmle uzunluƒüu, kelime tekrarƒ±, baƒüla√ß kullanƒ±mƒ± ve anlamsal tutarlƒ±lƒ±k gibi dilsel √∂l√ß√ºtlere g√∂re analiz eder.
        Doƒüal Dil ƒ∞≈üleme (NLP) ve makine √∂ƒürenmesi teknikleri kullanƒ±larak, metindeki bili≈üsel bozukluk belirtilerini tespit etmeye yardƒ±mcƒ± olur.
        Amacƒ±mƒ±z, kullanƒ±cƒ±ya erken uyarƒ± niteliƒüinde bir risk deƒüerlendirmesi sunmak ve gerektiƒüinde saƒülƒ±k uzmanƒ±na y√∂nlendirmektir. Bu sistem tƒ±bbi tanƒ± koymaz, yalnƒ±zca √∂n deƒüerlendirme desteƒüi saƒülar.
    """)

elif sayfa == "üß† Analiz Yap":
    st.header("üìù A√ßƒ±k U√ßlu Sorularla Alzheimer Riski Analizi")
    st.markdown("A≈üaƒüƒ±daki sorularƒ± sƒ±rayla yanƒ±tlayƒ±nƒ±z. L√ºtfen olabildiƒüince doƒüal ve ayrƒ±ntƒ±lƒ± cevaplar verin.")

    sorular = [
        "1. Nasƒ±lsƒ±nƒ±z, g√ºn√ºn√ºz nasƒ±l ge√ßti?",
        "2. Ge√ßen hafta seni en √ßok mutlu eden ≈üey neydi?",
        "3. √áocukluƒüunuzda en √ßok hatƒ±rladƒ±ƒüƒ±nƒ±z anƒ± nedir?",
        "4. Hayatƒ±nƒ±z boyunca sizi en √ßok etkileyen ki≈üi kimdi? Neden?",
        "5. Ailenizle ili≈ükileriniz nasƒ±l? Onlardan bahsedebilir misiniz?",
        "6. Eƒüer ge√ßmi≈üe d√∂n√ºp bir ≈üeyi deƒüi≈ütirebilseydiniz neyi deƒüi≈ütirirdiniz?",
        "7. Gelecek hafta i√ßin planlarƒ±n neler?",
        "8. Haftasonu hava √ßok g√ºzel olursa neler yaparsƒ±n, kimlerle vakit ge√ßirirsin?",
        "9. En b√ºy√ºk hayaliniz nedir?",
        "10. Bu g√∂rselde neler g√∂r√ºyorsunuz?"
    ]

    if 'soru_index' not in st.session_state:
        st.session_state.soru_index = 0
    if 'cevaplar' not in st.session_state:
        st.session_state.cevaplar = [""] * len(sorular)

    index = st.session_state.soru_index
    st.write(f"**{sorular[index]}**")

    if index == 9: 
        image_path = "C:\\veri.modelleri\\kurabiye.hirsizi.jpeg"
        if os.path.exists(image_path):
            st.image(image_path, caption="Soru 10 G√∂rseli", width=450)
        else:
            st.error(f"G√∂rsel bulunamadƒ±: {image_path}")

    st.session_state.cevaplar[index] = st.text_area(
        "Cevabƒ±nƒ±z:", 
        value=st.session_state.cevaplar[index], 
        height=150,
        key=f"cevap_{index}"
    )

    col1, col2 = st.columns([1, 1])
    with col1:
        if index > 0 and st.button("‚¨ÖÔ∏è Geri"):
            st.session_state.soru_index -= 1
            st.rerun()
            
    with col2:
        if index < len(sorular) - 1:
            if st.button("‚û°Ô∏è ƒ∞leri"):
                st.session_state.soru_index += 1
                st.rerun()
        else:
            if st.button("üîç Analizi Ba≈ülat"):
                metin = " ".join(st.session_state.cevaplar)

                if metin.strip() == "":
                    st.warning("L√ºtfen en az bir soruyu yanƒ±tlayƒ±n.")
                else:
                    st.success("Analiz tamamlandƒ±.")

                    st.markdown("---")
                    st.subheader("üß† Konsolide Alzheimer Riski Tahmin Sonucu")

                    if zamir_model and zamir_tokenizer and sond_model and sond_tokenizer:
                        final_risk_seviyesi = konsolide_analiz_yap(metin, zamir_model, zamir_tokenizer, sond_model, sond_tokenizer)
                        
                        etiketler = {0: "üü¢ Risk Yok", 1: "‚ö†Ô∏è Orta Risk", 2: "üî¥ Y√ºksek Risk"}
                        
                        st.markdown(f"### **Tahmin: {etiketler.get(final_risk_seviyesi, 'Bilinmiyor')}**")
                        
                        st.markdown("""
                        **Not:** Bu sonu√ß, birden fazla modelin ve manuel analizin bulgularƒ±nƒ± birle≈ütirerek olu≈üturulmu≈ütur.
                        Bu bir tƒ±bbi te≈ühis deƒüildir ve yalnƒ±zca bilgilendirme ama√ßlƒ±dƒ±r.
                        """)
                    else:
                        st.warning("Gerekli modeller y√ºklenemediƒüi i√ßin analiz yapƒ±lamadƒ±.")

elif sayfa == "‚ùì Nasƒ±l √áalƒ±≈üƒ±r":
    st.header("üîß Uygulama Nasƒ±l √áalƒ±≈üƒ±yor?")

    with st.expander("üìå Model Hakkƒ±nda"):
        st.markdown("""
        - Alzheimer hastalƒ±ƒüƒ± yedi a≈üamada incelenir. Hastalƒ±k ilerledik√ße dikkat eksikliƒüi, anlama g√º√ßl√ºƒü√º ve √∂zellikle dil bozukluklarƒ± gibi semptomlar giderek belirginle≈üir.
        - Ara≈ütƒ±rmalar, Alzheimer tanƒ±sƒ± konulmadan √ßok √∂nce, bili≈üsel gerileme ba≈ülamadan √∂nce bile temel dil i≈ülevlerinde se√ßici bozulmalarƒ±n ortaya √ßƒ±ktƒ±ƒüƒ±nƒ± g√∂stermektedir. Bu da dil bozukluklarƒ±nƒ±n hastalƒ±ƒüƒ±n erken ve √∂zg√ºn belirtilerinden biri olduƒüunu ortaya koymaktadƒ±r.
        - Konu≈üma transkriptleri √ºzerinde makine √∂ƒürenimi ve doƒüal dil i≈üleme teknikleri kullanƒ±larak Alzheimer riski deƒüerlendirmesi yapƒ±lmaktadƒ±r. Bu y√∂ntemler, hastalƒ±ƒüƒ±n erken te≈ühisinde etkili ve giderek yaygƒ±nla≈üan ara√ßlar olarak √∂nem kazanmaktadƒ±r.
        """)

    with st.expander("üìñ Kaynak√ßa"):
        st.markdown("""
        - https://onlinelibrary.wiley.com/doi/abs/10.1002/gps.3766?casa_token=AOxnPF4HTdoAAAAA:iVVSenAAV3yJmpm36O_9dzHdUmHfvko9-Z8CgBfXpBtN5U8FFb_ChcObapeiu9TpJF-LWAAHQJvVt8Y
        - E. Akarsu Ve Ark. , "Alzheimer's Disease Detection and Dataset Creation from Spontaneous Speech Spontane Konu≈ümadan Alzheimer Hastalƒ±ƒüƒ± Tespiti ve Veri Seti Olu≈üturma," 32nd IEEE Conference on Signal Processing and Communications Applications, SIU 2024 , Mersin, T√ºrkiye, 2024
        """)

elif sayfa == "üìû ƒ∞leti≈üim":
    st.header("üìß Bize Ula≈üƒ±n")
    st.markdown("Sorularƒ±nƒ±z veya i≈ü birliƒüi i√ßin bizimle ileti≈üime ge√ßebilirsiniz.")
    st.markdown("**E-posta:** üì´ atomnoktavirgul@gmail.com")
